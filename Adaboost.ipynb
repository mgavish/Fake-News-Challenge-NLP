{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "#pd.set_option('display.max_rows', None)\n",
    "# pd.options.display.float_format = '{:, .2f}'.format\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import numpy as np\n",
    "from numpy import save, load\n",
    "from numpy import savez_compressed\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "#from scipy.misc import comb, logsumexp\n",
    "from sklearn.manifold import TSNE #a tool to visualize high dimensional data\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD # dimensionality reduction using truncated SVD (AKA LSA)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.collocations import *\n",
    "import string #python module\n",
    "import re # python regex module\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changed to using npz instead of pickle after finding npz average save/load times are shorter than pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75385,)\n",
      "(75385, 836)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "from numpy import load\n",
    "target_y = load('model_target_data.npz')\n",
    "target_y = target_y['arr_0']\n",
    "target_y = np.ravel(target_y)\n",
    "print(target_y.shape)\n",
    "\n",
    "features_x =  load('model_data.npz')\n",
    "features_x = features_x['arr_0']\n",
    "print(features_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25773\n",
      "463657257\n"
     ]
    }
   ],
   "source": [
    "print(os.path.getsize('model_target_data.npz'))\n",
    "print(os.path.getsize('model_data.npz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 5min 55s, sys: 1min 30s, total: 1h 7min 25s\n",
      "Wall time: 1h 7min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtClf = DecisionTreeClassifier(max_depth = 1)\n",
    "Ada_clf_1 = AdaBoostClassifier(base_estimator = dtClf, n_estimators = 100, learning_rate = 1.0 ) # n_estimators = number of weak learners/trees in the forest of trees\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "Ada_clf_1_scores = cross_val_predict(Ada_clf_1, features_x, target_y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score using provided metrics in scorer.py (provided in https://github.com/FakeNewsChallenge/fnc-1) on TEST set\n",
    "from score import report_score, LABELS, score_submission\n",
    "\n",
    "predicted = [LABELS[int(a)] for a in Ada_clf_1_scores]\n",
    "actual = [LABELS[int(a)] for a in target_y]\n",
    "fold_score, _ = score_submission(actual, predicted)\n",
    "max_fold_score, _ = score_submission(actual, actual)\n",
    "score = fold_score/max_fold_score\n",
    "\n",
    "best_score = 0\n",
    "best_fold = None\n",
    "    \n",
    "#print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
    "if score > best_score:\n",
    "    best_score = score\n",
    "    best_fold = Ada_clf_1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |   2269    |    814    |   2341    |    157    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    399    |    527    |    575    |    36     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |   1957    |    797    |   9971    |    648    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    25     |    16     |    398    |   54455   |\n",
      "-------------------------------------------------------------\n",
      "Score: 28101.5 out of 34214.5\t(82.1333060544506%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.1333060544506"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_score(actual,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.3min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.3min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=1.0, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=1.0, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.1min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.1min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.8min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.5, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.5, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.1min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=150 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=150, total= 1.0min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=200 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=200, total= 1.4min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n",
      "[CV] clf__learning_rate=0.1, clf__n_estimators=250 ...................\n",
      "[CV] .... clf__learning_rate=0.1, clf__n_estimators=250, total= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed: 129.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('pca',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=27, random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('clf',\n",
       "                                        AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                           base_estimator=None,\n",
       "                                                           learning_rate=1.0,\n",
       "                                                           n_estimators=50,\n",
       "                                                           random_state=123))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'clf__learning_rate': [1.0, 0.5, 0.1],\n",
       "                         'clf__n_estimators': [150, 200, 250]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_ab = Pipeline([('pca', PCA(n_components=27)),\n",
    "            ('clf', AdaBoostClassifier(random_state = 123))])\n",
    "\n",
    "# Set grid search params\n",
    "adaboost_param_grid = {\n",
    "    'clf__n_estimators': [150, 200, 250],\n",
    "    'clf__learning_rate': [1.0, 0.5, 0.1]\n",
    "}\n",
    "\n",
    "# Construct grid search\n",
    "gs_ab = GridSearchCV(estimator=pipe_ab,\n",
    "            param_grid=adaboost_param_grid,\n",
    "            scoring='accuracy',\n",
    "            cv=10, verbose=2, return_train_score = True)\n",
    "\n",
    "# Fit using grid search\n",
    "gs_ab.fit(features_x, target_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=27,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('clf',\n",
       "                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                    learning_rate=0.5, n_estimators=200,\n",
       "                                    random_state=123))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ab.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchcv found best score of 0.8991577167438966 with a learning rate of 0.5 and 200 trees\n"
     ]
    }
   ],
   "source": [
    "print(\"GridSearchcv found best score of \" + str(gs_ab.best_score_) + \" with a learning rate of 0.5 and 200 trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "max depth of 6, similar to xgboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7h 24min, sys: 1min 35s, total: 7h 25min 35s\n",
      "Wall time: 7h 25min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtClf_3 = DecisionTreeClassifier(max_depth = 6)\n",
    "Ada_clf_3 = AdaBoostClassifier(base_estimator = dtClf_3, n_estimators = 100, learning_rate = 1.0 ) # n_estimators = number of weak learners/trees in the forest of trees\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "Ada_clf_3_scores = cross_val_predict(Ada_clf_3, features_x, target_y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score using provided metrics in scorer.py (provided in https://github.com/FakeNewsChallenge/fnc-1) on TEST set\n",
    "from score import report_score, LABELS, score_submission\n",
    "\n",
    "predicted_3 = [LABELS[int(a)] for a in Ada_clf_3_scores]\n",
    "actual_3 = [LABELS[int(a)] for a in target_y]\n",
    "fold_score_3, _3 = score_submission(actual, predicted)\n",
    "max_fold_score_3, _3 = score_submission(actual_3, actual_3)\n",
    "score_3 = fold_score_3/max_fold_score_3\n",
    "\n",
    "best_score_3 = 0\n",
    "best_fold_3 = None\n",
    "    \n",
    "#print(\"Score for fold \"+ str(fold) + \" was - \" + str(score))\n",
    "if score_3 > best_score_3:\n",
    "    best_score_3 = score_3\n",
    "    best_fold_3 = Ada_clf_3_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |   3728    |    218    |   1577    |    58     |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    547    |    565    |    395    |    30     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |   1177    |    75     |   11915   |    206    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    39     |     1     |    510    |   54344   |\n",
      "-------------------------------------------------------------\n",
      "Score: 30791.25 out of 34214.5\t(89.99473907261542%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89.99473907261542"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_score(actual_3,predicted_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
